{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11812220,"sourceType":"datasetVersion","datasetId":7418943},{"sourceId":239697920,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0) install BERTScore\n!pip --quiet install bert-score\n!pip --quiet install qwen-vl-utils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:42:06.911659Z","iopub.execute_input":"2025-05-16T18:42:06.911876Z","iopub.status.idle":"2025-05-16T18:43:21.947370Z","shell.execute_reply.started":"2025-05-16T18:42:06.911857Z","shell.execute_reply":"2025-05-16T18:43:21.946362Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom transformers import Qwen2VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom bert_score import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:43:21.949673Z","iopub.execute_input":"2025-05-16T18:43:21.949897Z","iopub.status.idle":"2025-05-16T18:43:48.685457Z","shell.execute_reply.started":"2025-05-16T18:43:21.949876Z","shell.execute_reply":"2025-05-16T18:43:48.684547Z"}},"outputs":[{"name":"stderr","text":"2025-05-16 18:43:35.341364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747421015.546727      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747421015.606348      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1) loading QA dataset\ndf = pd.read_csv(\"/kaggle/input/test-data-curation/qa_dataset.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:43:48.686338Z","iopub.execute_input":"2025-05-16T18:43:48.687068Z","iopub.status.idle":"2025-05-16T18:43:48.720096Z","shell.execute_reply.started":"2025-05-16T18:43:48.687043Z","shell.execute_reply":"2025-05-16T18:43:48.718904Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 2) device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:43:48.721196Z","iopub.execute_input":"2025-05-16T18:43:48.721532Z","iopub.status.idle":"2025-05-16T18:43:48.725962Z","shell.execute_reply.started":"2025-05-16T18:43:48.721473Z","shell.execute_reply":"2025-05-16T18:43:48.725039Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 3) load Qwen2‐VL‐2B‐Instruct baseline\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n\nmodel = model.to(device).eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:43:48.727064Z","iopub.execute_input":"2025-05-16T18:43:48.727381Z","iopub.status.idle":"2025-05-16T18:44:24.563057Z","shell.execute_reply.started":"2025-05-16T18:43:48.727342Z","shell.execute_reply":"2025-05-16T18:44:24.562334Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179c32fa62f741509b6d5821a1ae8b5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1140e148f7134db4989bd88a43b43ace"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e38489b47fa42d88f2934014f309d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2553bb1c2f41a18d01c9100812f05a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e18b8c0cf74e93bf9906a788b5f9eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce24c073e6a4feeb2e9b72768910264"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"120134b69e9f4e24964c5631124c2d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5acf7a117af84f62b0677082a0003f78"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12531bed79a24db2900b0ee160fcab9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff84bb0bc2c6437983af67a8c32c5249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1285afc01a4e9d9f36cb519953ea93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be8b2db47e9b49578cfad1b18c817a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f7aee31c0a242cda1b9d130a9cdb28e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import math\n\n# 1) parameters\nbatch_size  = 8\npreds, refs = [], []\nimage_root  = \"/kaggle/input/test-data-dataset/images\"\nn_samples   = len(df)\nn_batches   = math.ceil(n_samples / batch_size)\n\n# 2) batched inference\nstart_time = time.time()\nfor batch_start in tqdm(range(0, n_samples, batch_size),\n                        total=n_batches,\n                        desc=\"Qwen2-VL Batched Inference\"):\n    batch_df = df.iloc[batch_start : batch_start + batch_size]\n\n    # 2a) build list of “chat” messages for the batch\n    batch_messages = []\n    for _, row in batch_df.iterrows():\n        img = Image.open(os.path.join(image_root, row[\"path\"])).convert(\"RGB\").resize((256, 256))\n        batch_messages.append([\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\",  \"text\":f\"Answer in exactly one word.{row['question']}\"  }\n            ]}\n        ])\n\n    # 2b) apply the chat template in batch\n    batch_texts = [\n        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n        for msg in batch_messages\n    ]\n\n    # 2c) extract vision inputs for the whole batch\n    image_inputs, video_inputs = process_vision_info(batch_messages)\n\n    # 2d) tokenize the entire batch at once\n    inputs = processor(\n        text=batch_texts,\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n    ).to(device)\n\n    # 2e) generate in one shot\n    with torch.inference_mode():\n        generated = model.generate(**inputs, max_new_tokens=32)\n\n    # 2f) decode each example, trimming off the prompt\n    for in_ids, out_ids in zip(inputs.input_ids, generated):\n        trimmed_ids = out_ids[len(in_ids):]\n        text_out   = processor.batch_decode(\n            [trimmed_ids],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=False\n        )[0].strip()\n        preds.append(text_out)\n\n    # 2g) collect references\n    refs.extend(batch_df[\"answer\"].astype(str).str.strip().tolist())\n\nend_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:50:55.941976Z","iopub.execute_input":"2025-05-16T18:50:55.942613Z","iopub.status.idle":"2025-05-16T19:11:04.848466Z","shell.execute_reply.started":"2025-05-16T18:50:55.942581Z","shell.execute_reply":"2025-05-16T19:11:04.847544Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Qwen2-VL Batched Inference:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3953d5424b784572b865db312a1ecfba"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# # 4) inference loop with timing\n# preds, refs = [], []\n# image_root  = \"/kaggle/input/test-data-dataset/images\"\n\n# start_time = time.time()\n# for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Qwen2-VL Inference\"):\n#     # load & preprocess image\n#     img_path = os.path.join(image_root, row[\"path\"])\n#     image    = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n    \n#     # build the chat‐style message\n#     messages = [\n#         {\n#             \"role\": \"user\",\n#             \"content\": [\n#                 {\"type\": \"image\", \"image\": image},\n#                 {\"type\": \"text\",  \"text\":  row[\"question\"]}\n#             ],\n#         }\n#     ]\n#     # apply template\n#     text = processor.apply_chat_template(\n#         messages, tokenize=False, add_generation_prompt=True\n#     )\n#     # extract vision inputs\n#     image_inputs, video_inputs = process_vision_info(messages)\n#     # tokenize & move to device\n#     inputs = processor(\n#         text=[text],\n#         images=image_inputs,\n#         videos=video_inputs,\n#         padding=True,\n#         return_tensors=\"pt\",\n#     ).to(device)\n\n#     # generate\n#     with torch.inference_mode():\n#         generated_ids = model.generate(**inputs, max_new_tokens=32)\n\n#     # trim off prompt tokens\n#     trimmed_ids = [\n#         out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n#     ]\n#     output_text = processor.batch_decode(\n#         trimmed_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n#     )\n#     pred = output_text[0].strip()\n\n#     preds.append(pred)\n#     refs.append(str(row[\"answer\"]).strip())\n\n# end_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:11:04.849908Z","iopub.execute_input":"2025-05-16T19:11:04.850440Z","iopub.status.idle":"2025-05-16T19:11:04.855685Z","shell.execute_reply.started":"2025-05-16T19:11:04.850419Z","shell.execute_reply":"2025-05-16T19:11:04.854405Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# 5) compute metrics\ntotal_time    = end_time - start_time\navg_time_ms   = total_time / len(preds) * 1000\n\n# Exact‐Match Accuracy\nexact_match = sum(p.lower()==r.lower() for p,r in zip(preds, refs)) / len(preds)\n\n# BERTScore F1 (all preds)\nP_all, R_all, F1_all = score(preds, refs, lang=\"en\", rescale_with_baseline=True)\nbert_f1_all = F1_all.mean().item()\n\n# One‐word analysis\nis_one_word  = [((\" \" not in p) and p!= \"\") for p in preds]\npct_one_word = sum(is_one_word) / len(preds) * 100\npreds_1w     = [p for p, ok in zip(preds, is_one_word) if ok]\nrefs_1w      = [r for r, ok in zip(refs,  is_one_word) if ok]\n\nif preds_1w:\n    _, _, F1_1w = score(preds_1w, refs_1w, lang=\"en\", rescale_with_baseline=True)\n    bert_f1_1w = F1_1w.mean().item()\nelse:\n    bert_f1_1w = float(\"nan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:11:04.856460Z","iopub.execute_input":"2025-05-16T19:11:04.856784Z","iopub.status.idle":"2025-05-16T19:11:22.559083Z","shell.execute_reply.started":"2025-05-16T19:11:04.856759Z","shell.execute_reply":"2025-05-16T19:11:22.558376Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7dea2702ba4ff7a7332d7c744fcd97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5d197aec6bf423f88a96ddad42f3a17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ec2ca3d86bf4611b0bea71e9050d079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e0ed058e13443f9d447c96b57c6b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfdc9dfc61934311ba893240c3c447f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e54179315a4dd0bf60c61f9b2b253d"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 6) report\nprint(f\"Total inference time (1000 samples): {total_time:.1f}s\")\nprint(f\"Average per sample:                {avg_time_ms:.1f}ms\\n\")\nprint(f\"Exact-Match Accuracy:              {exact_match:.2f}\")\nprint(f\"BERTScore F1 (all preds):          {bert_f1_all:.2f}\\n\")\nprint(f\"% One-Word Predictions:            {pct_one_word:.2f}%\")\nprint(f\"BERTScore F1 (one-word only):      {bert_f1_1w:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:11:22.560781Z","iopub.execute_input":"2025-05-16T19:11:22.561020Z","iopub.status.idle":"2025-05-16T19:11:22.566549Z","shell.execute_reply.started":"2025-05-16T19:11:22.561002Z","shell.execute_reply":"2025-05-16T19:11:22.565725Z"}},"outputs":[{"name":"stdout","text":"Total inference time (1000 samples): 1208.9s\nAverage per sample:                201.7ms\n\nExact-Match Accuracy:              0.57\nBERTScore F1 (all preds):          0.78\n\n% One-Word Predictions:            89.22%\nBERTScore F1 (one-word only):      0.86\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}