{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11812220,"sourceType":"datasetVersion","datasetId":7418943},{"sourceId":239697920,"sourceType":"kernelVersion"},{"sourceId":240061586,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0) install the BERTScore metric\n!pip --quiet install bert-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:45:37.613255Z","iopub.execute_input":"2025-05-16T22:45:37.613473Z","iopub.status.idle":"2025-05-16T22:46:58.307106Z","shell.execute_reply.started":"2025-05-16T22:45:37.613455Z","shell.execute_reply":"2025-05-16T22:46:58.306426Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom transformers import AutoProcessor, PaliGemmaForConditionalGeneration\nfrom bert_score import score\nfrom peft import PeftModel\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:46:58.308010Z","iopub.execute_input":"2025-05-16T22:46:58.308206Z","iopub.status.idle":"2025-05-16T22:47:24.768166Z","shell.execute_reply.started":"2025-05-16T22:46:58.308184Z","shell.execute_reply":"2025-05-16T22:47:24.767625Z"}},"outputs":[{"name":"stderr","text":"2025-05-16 22:47:09.619493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747435629.833932      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747435629.896630      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1) load your QA dataset\ndf = pd.read_csv(\"/kaggle/input/test-data-curation/qa_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:47:24.769698Z","iopub.execute_input":"2025-05-16T22:47:24.770111Z","iopub.status.idle":"2025-05-16T22:47:24.793424Z","shell.execute_reply.started":"2025-05-16T22:47:24.770094Z","shell.execute_reply":"2025-05-16T22:47:24.792946Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:47:24.793982Z","iopub.execute_input":"2025-05-16T22:47:24.794227Z","iopub.status.idle":"2025-05-16T22:47:24.893837Z","shell.execute_reply.started":"2025-05-16T22:47:24.794201Z","shell.execute_reply":"2025-05-16T22:47:24.893362Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 2) device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:47:24.894447Z","iopub.execute_input":"2025-05-16T22:47:24.894649Z","iopub.status.idle":"2025-05-16T22:47:24.897979Z","shell.execute_reply.started":"2025-05-16T22:47:24.894633Z","shell.execute_reply":"2025-05-16T22:47:24.897230Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n\n# 1) Load the base PaliGemma-3B-pt-224 in FP16 (or full-precision if you prefer)\nbase_model = PaliGemmaForConditionalGeneration.from_pretrained(\n    \"google/paligemma-3b-mix-224\",   # or your local base folder\n    torch_dtype=torch.float16,           # → load in half-precision\n    device_map=\"auto\",                   # → shard across your GPUs/TPUs\n    low_cpu_mem_usage=True               # → speed up init + lower host memory\n)\n\n# 2) Plug in your fine-tuned LoRA adapter\nlora_dir = \"/kaggle/input/16-may-paligemma-mix/finetuned_paligemma_mix/lora_adapters\"\nmodel = PeftModel.from_pretrained(\n    base_model,\n    lora_dir,\n    torch_dtype=torch.float16,           # ensure the adapter is also in half-precision\n    device_map=\"auto\"\n)\nmodel.eval()\n\n# 3) Reload the processor (image+text) so it matches your base model’s preproc\nprocessor = AutoProcessor.from_pretrained(\n    \"google/paligemma-3b-mix-224\",   # same ID or local folder as in step 1\n    local_files_only=False              # remove if you want strictly offline\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:47:24.898694Z","iopub.execute_input":"2025-05-16T22:47:24.899131Z","iopub.status.idle":"2025-05-16T22:48:23.426154Z","shell.execute_reply.started":"2025-05-16T22:47:24.899107Z","shell.execute_reply":"2025-05-16T22:48:23.425601Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93398c4930f43b2a7445cd6becd4b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28044019aae342579dbbd4970c6a2278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed4c73c3cfc04d6bbe17c8a24aa33240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fe7c4d1ec7457dbdd0563d9354f2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10136f390614e63917b93fc7d564a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d682a5c71a884c738681103d8e18ab75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992833638e2c4108bf3c3d9a836aff3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d80dbca634744f8f8399cbb7fb78d456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3094917961d6472ab8714d741a08b745"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21adb52051b347ec8d3f046a37b2a7b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"506b5d33443c4e98ac5c69833787bb86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96579a002f424fcc9d76f84d6562467f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da12d34aa61f4f35aa322afeff16a575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/607 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2202f0bbc7b48b5b70dc537ddbe7019"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n# 4) inference loop with progress bar\npreds, refs = [], []\nimage_root  = \"/kaggle/input/test-data-dataset/images\"\n\nstart_time = time.time()\n\nfor _, row in tqdm(df.iterrows(), total=len(df), desc=\"PaliGemma Inference\"):\n    # load & preprocess image\n    img_path = os.path.join(image_root, row[\"path\"])\n    image    = Image.open(img_path).convert(\"RGB\")\n    \n     # build the prompted question with the required <image> token\n    question    = row[\"question\"]\n    # 1 <image> token because you have 1 image\n    prompt_text = f\"<image> Answer in exactly one word: {question}\"\n    \n    # tokenize image + prompt\n    inputs    = processor(text=prompt_text, images=image, return_tensors=\"pt\").to(device)\n    input_len = inputs[\"input_ids\"].shape[-1]\n    \n    # generate (greedy)\n    with torch.inference_mode():\n        output_ids = model.generate(**inputs, max_new_tokens=20, do_sample=False)\n    \n    # decode only the answer portion\n    answer_ids = output_ids[0, input_len:]\n    pred       = processor.decode(answer_ids, skip_special_tokens=True).strip()\n    \n    preds.append(pred)\n    refs .append(str(row[\"answer\"]).strip())\n\nend_time = time.time()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T22:48:23.426866Z","iopub.execute_input":"2025-05-16T22:48:23.427127Z","iopub.status.idle":"2025-05-16T23:10:32.046901Z","shell.execute_reply.started":"2025-05-16T22:48:23.427103Z","shell.execute_reply":"2025-05-16T23:10:32.046092Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"PaliGemma Inference:   0%|          | 0/5994 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6732dd4e2f4caf8af12299d12ee000"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# 4) compute metrics\ntotal_time    = end_time - start_time\navg_time_ms   = total_time / len(preds) * 1000\n\n# Exact‐Match Accuracy (0–1)\nexact_match = sum(p.lower()==r.lower() for p,r in zip(preds, refs)) / len(preds)\n\n# BERTScore F1 for all predictions\n_, _, F1_all = score(preds, refs, lang=\"en\", rescale_with_baseline=True)\nbert_f1_all  = F1_all.mean().item()\n\n# One‐word compliance & BERTScore on one‐word preds\nis_one_word = [((\" \" not in p) and p != \"\") for p in preds]\npct_one_word = sum(is_one_word) / len(preds) * 100\n\npreds_1w = [p for p, ok in zip(preds, is_one_word) if ok]\nrefs_1w  = [r for r, ok in zip(refs,  is_one_word) if ok]\n\nif preds_1w:\n    _, _, F1_1w = score(preds_1w, refs_1w, lang=\"en\", rescale_with_baseline=True)\n    bert_f1_1w  = F1_1w.mean().item()\nelse:\n    bert_f1_1w = float(\"nan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T23:10:32.047821Z","iopub.execute_input":"2025-05-16T23:10:32.048106Z","iopub.status.idle":"2025-05-16T23:10:54.088613Z","shell.execute_reply.started":"2025-05-16T23:10:32.048079Z","shell.execute_reply":"2025-05-16T23:10:54.087828Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00286e02bea24a0b9c8e28f6f9e8dd9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b372d1b99354cd18ff1d5c2eec02894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b71d1e67394c6789398933cd989db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b519563032848da88c29327318d6fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03f24c35ccb6420e8f1a377557dcaf61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989de6f9c62f460dab75c16ed4f56779"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 5) report\nprint(f\"Total inference time (1000 samples): {total_time:.1f}s\")\nprint(f\"Average per sample:                 {avg_time_ms:.1f}ms\\n\")\nprint(f\"Exact-Match Accuracy:               {exact_match:.2f}\")\nprint(f\"BERTScore F1 (all preds):           {bert_f1_all:.2f}\\n\")\nprint(f\"% One-Word Predictions:             {pct_one_word:.2f}%\")\nprint(f\"BERTScore F1 (one-word only):       {bert_f1_1w:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T23:10:54.090796Z","iopub.execute_input":"2025-05-16T23:10:54.091019Z","iopub.status.idle":"2025-05-16T23:10:54.095686Z","shell.execute_reply.started":"2025-05-16T23:10:54.091002Z","shell.execute_reply":"2025-05-16T23:10:54.094890Z"}},"outputs":[{"name":"stdout","text":"Total inference time (1000 samples): 1328.6s\nAverage per sample:                 221.7ms\n\nExact-Match Accuracy:               0.78\nBERTScore F1 (all preds):           0.91\n\n% One-Word Predictions:             99.93%\nBERTScore F1 (one-word only):       0.91\n","output_type":"stream"}],"execution_count":9}]}