{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11812220,"sourceType":"datasetVersion","datasetId":7418943},{"sourceId":239697920,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0) install BERTScore\n!pip --quiet install bert-score\n!pip --quiet install qwen-vl-utils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:18:13.301744Z","iopub.execute_input":"2025-05-16T19:18:13.302345Z","iopub.status.idle":"2025-05-16T19:19:37.224397Z","shell.execute_reply.started":"2025-05-16T19:18:13.302294Z","shell.execute_reply":"2025-05-16T19:19:37.223639Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom bert_score import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:19:37.225830Z","iopub.execute_input":"2025-05-16T19:19:37.226066Z","iopub.status.idle":"2025-05-16T19:20:01.449707Z","shell.execute_reply.started":"2025-05-16T19:19:37.226042Z","shell.execute_reply":"2025-05-16T19:20:01.449148Z"}},"outputs":[{"name":"stderr","text":"2025-05-16 19:19:50.177198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747423190.357278      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747423190.411497      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1) loading QA dataset\ndf = pd.read_csv(\"/kaggle/input/test-data-curation/qa_dataset.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:20:01.450355Z","iopub.execute_input":"2025-05-16T19:20:01.450892Z","iopub.status.idle":"2025-05-16T19:20:01.474484Z","shell.execute_reply.started":"2025-05-16T19:20:01.450873Z","shell.execute_reply":"2025-05-16T19:20:01.473787Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 2) device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:20:01.475947Z","iopub.execute_input":"2025-05-16T19:20:01.476161Z","iopub.status.idle":"2025-05-16T19:20:01.488904Z","shell.execute_reply.started":"2025-05-16T19:20:01.476144Z","shell.execute_reply":"2025-05-16T19:20:01.488203Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n    torch_dtype=torch.float16,   # or bfloat16 if that’s what you want\n    # no device_map\n)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n\n# set padding as before\nprocessor.tokenizer.pad_token     = processor.tokenizer.eos_token\nprocessor.tokenizer.padding_side  = \"left\"\n\nmodel = model.to(device).eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:20:01.489652Z","iopub.execute_input":"2025-05-16T19:20:01.489863Z","iopub.status.idle":"2025-05-16T19:21:10.998168Z","shell.execute_reply.started":"2025-05-16T19:20:01.489838Z","shell.execute_reply":"2025-05-16T19:21:10.997609Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"598c47b00dc447e0a7cef05931d50567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cc489d5d484180b90b342a139e8795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ff9a1d0ccf4a58aea8b0235daf954d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e779e34b85a04194aaf6baf7ad1e7170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a08a869f5924a5e992c6a55d403c08a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4ceedd59144e10bb2d04a6425c5b49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aae462b109a4d768d8fe2f00b1519e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ac9064fc1a41ed843e03cd794f86d1"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/5.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c5a4d63bd774928988979de0dd5842b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bf2b61d3dd7460cae3ccfd7af353130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff5f769f86d4754a9471da7b594be3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15cf9378b621492699f904dbca01cefb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741ba59273f24ce08e9718d54e95acde"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import math\n\n# 1) parameters\nbatch_size  = 16\npreds, refs = [], []\nimage_root  = \"/kaggle/input/test-data-dataset/images\"\nn_samples   = len(df)\nn_batches   = math.ceil(n_samples / batch_size)\n\n# 2) batched inference\nstart_time = time.time()\nfor batch_start in tqdm(range(0, n_samples, batch_size),\n                        total=n_batches,\n                        desc=\"Qwen2.5-VL-3B-Instruct Batched Inference\"):\n    batch_df = df.iloc[batch_start : batch_start + batch_size]\n\n    # 2a) build list of “chat” messages for the batch\n    batch_messages = []\n    for _, row in batch_df.iterrows():\n        img = Image.open(os.path.join(image_root, row[\"path\"])).convert(\"RGB\").resize((256, 256))\n        batch_messages.append([\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\",  \"text\": f\"Answer in exactly one word:{row['question']}\"}\n            ]}\n        ])\n\n    # 2b) apply the chat template in batch\n    batch_texts = [\n        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n        for msg in batch_messages\n    ]\n\n    # 2c) extract vision inputs for the whole batch\n    image_inputs, video_inputs = process_vision_info(batch_messages)\n\n    # 2d) tokenize the entire batch at once\n    inputs = processor(\n        text=batch_texts,\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n    ).to(device)\n\n    # 2e) generate in one shot\n    with torch.inference_mode():\n        generated = model.generate(**inputs, max_new_tokens=32)\n\n    # 2f) decode each example, trimming off the prompt\n    for in_ids, out_ids in zip(inputs.input_ids, generated):\n        trimmed_ids = out_ids[len(in_ids):]\n        text_out   = processor.batch_decode(\n            [trimmed_ids],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=False\n        )[0].strip()\n        preds.append(text_out)\n    # 2g) collect references\n    refs.extend(batch_df[\"answer\"].astype(str).str.strip().tolist())\n\nend_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:24:20.825624Z","iopub.execute_input":"2025-05-16T19:24:20.825920Z","iopub.status.idle":"2025-05-16T19:54:53.418165Z","shell.execute_reply.started":"2025-05-16T19:24:20.825898Z","shell.execute_reply":"2025-05-16T19:54:53.417276Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Qwen2.5-VL-3B-Instruct Batched Inference:   0%|          | 0/375 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33494888046e4bcea88cc66e0a2ed4da"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# # 4) inference loop with timing\n# preds, refs = [], []\n# image_root  = \"/kaggle/input/test-data-dataset/images\"\n\n# start_time = time.time()\n# for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Qwen2-VL Inference\"):\n#     # load & preprocess image\n#     img_path = os.path.join(image_root, row[\"path\"])\n#     image    = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n    \n#     # build the chat‐style message\n#     messages = [\n#         {\n#             \"role\": \"user\",\n#             \"content\": [\n#                 {\"type\": \"image\", \"image\": image},\n#                 {\"type\": \"text\",  \"text\":  row[\"question\"]}\n#             ],\n#         }\n#     ]\n#     # apply template\n#     text = processor.apply_chat_template(\n#         messages, tokenize=False, add_generation_prompt=True\n#     )\n#     # extract vision inputs\n#     image_inputs, video_inputs = process_vision_info(messages)\n#     # tokenize & move to device\n#     inputs = processor(\n#         text=[text],\n#         images=image_inputs,\n#         videos=video_inputs,\n#         padding=True,\n#         return_tensors=\"pt\",\n#     ).to(device)\n\n#     # generate\n#     with torch.inference_mode():\n#         generated_ids = model.generate(**inputs, max_new_tokens=32)\n\n#     # trim off prompt tokens\n#     trimmed_ids = [\n#         out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n#     ]\n#     output_text = processor.batch_decode(\n#         trimmed_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n#     )\n#     pred = output_text[0].strip()\n\n#     preds.append(pred)\n#     refs.append(str(row[\"answer\"]).strip())\n\n# end_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:54:53.419450Z","iopub.execute_input":"2025-05-16T19:54:53.419681Z","iopub.status.idle":"2025-05-16T19:54:53.424093Z","shell.execute_reply.started":"2025-05-16T19:54:53.419663Z","shell.execute_reply":"2025-05-16T19:54:53.423506Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# 5) compute metrics\ntotal_time    = end_time - start_time\navg_time_ms   = total_time / len(preds) * 1000\n\n# Exact‐Match Accuracy\nexact_match = sum(p.lower()==r.lower() for p,r in zip(preds, refs)) / len(preds)\n\n# BERTScore F1 (all preds)\nP_all, R_all, F1_all = score(preds, refs, lang=\"en\", rescale_with_baseline=True)\nbert_f1_all = F1_all.mean().item()\n\n# One‐word analysis\nis_one_word  = [((\" \" not in p) and p!= \"\") for p in preds]\npct_one_word = sum(is_one_word) / len(preds) * 100\npreds_1w     = [p for p, ok in zip(preds, is_one_word) if ok]\nrefs_1w      = [r for r, ok in zip(refs,  is_one_word) if ok]\n\nif preds_1w:\n    _, _, F1_1w = score(preds_1w, refs_1w, lang=\"en\", rescale_with_baseline=True)\n    bert_f1_1w = F1_1w.mean().item()\nelse:\n    bert_f1_1w = float(\"nan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:54:53.424846Z","iopub.execute_input":"2025-05-16T19:54:53.425078Z","iopub.status.idle":"2025-05-16T19:55:10.298595Z","shell.execute_reply.started":"2025-05-16T19:54:53.425053Z","shell.execute_reply":"2025-05-16T19:55:10.297818Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"579dc5be226546b1817f28432507aad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa60a13af3e49f9bdedf95a9ec0e6d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c3853395cb47589228bc079dd4a005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9f67a9cda741bfb2eb8acdfd5ea378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"671989e881214078981d8e0f5ce32522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc49637ad7b42d7a3cddd29b42aa5a2"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 6) report\nprint(f\"Total inference time (1000 samples): {total_time:.1f}s\")\nprint(f\"Average per sample:                {avg_time_ms:.1f}ms\\n\")\nprint(f\"Exact-Match Accuracy:              {exact_match:.2f}\")\nprint(f\"BERTScore F1 (all preds):          {bert_f1_all:.2f}\\n\")\nprint(f\"% One-Word Predictions:            {pct_one_word:.2f}%\")\nprint(f\"BERTScore F1 (one-word only):      {bert_f1_1w:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:55:10.300486Z","iopub.execute_input":"2025-05-16T19:55:10.300704Z","iopub.status.idle":"2025-05-16T19:55:10.304941Z","shell.execute_reply.started":"2025-05-16T19:55:10.300688Z","shell.execute_reply":"2025-05-16T19:55:10.304349Z"}},"outputs":[{"name":"stdout","text":"Total inference time (1000 samples): 1832.6s\nAverage per sample:                305.7ms\n\nExact-Match Accuracy:              0.43\nBERTScore F1 (all preds):          0.74\n\n% One-Word Predictions:            89.52%\nBERTScore F1 (one-word only):      0.81\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}