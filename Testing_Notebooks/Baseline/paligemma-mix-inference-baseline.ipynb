{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11812220,"sourceType":"datasetVersion","datasetId":7418943},{"sourceId":239697920,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0) install the BERTScore metric\n!pip --quiet install bert-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:50:05.105274Z","iopub.execute_input":"2025-05-17T21:50:05.105517Z","iopub.status.idle":"2025-05-17T21:51:17.901325Z","shell.execute_reply.started":"2025-05-17T21:50:05.105494Z","shell.execute_reply":"2025-05-17T21:51:17.900452Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom transformers import AutoProcessor, PaliGemmaForConditionalGeneration\nfrom bert_score import score\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:51:17.902262Z","iopub.execute_input":"2025-05-17T21:51:17.902476Z","iopub.status.idle":"2025-05-17T21:51:42.593763Z","shell.execute_reply.started":"2025-05-17T21:51:17.902453Z","shell.execute_reply":"2025-05-17T21:51:42.593210Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 21:51:27.952289: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747518688.138065      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747518688.189949      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1) load your QA dataset\ndf = pd.read_csv(\"/kaggle/input/test-data-curation/qa_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:51:42.595228Z","iopub.execute_input":"2025-05-17T21:51:42.595654Z","iopub.status.idle":"2025-05-17T21:51:42.618562Z","shell.execute_reply.started":"2025-05-17T21:51:42.595638Z","shell.execute_reply":"2025-05-17T21:51:42.618054Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:51:42.619142Z","iopub.execute_input":"2025-05-17T21:51:42.619363Z","iopub.status.idle":"2025-05-17T21:51:42.988652Z","shell.execute_reply.started":"2025-05-17T21:51:42.619347Z","shell.execute_reply":"2025-05-17T21:51:42.987989Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 2) device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:51:42.989369Z","iopub.execute_input":"2025-05-17T21:51:42.989611Z","iopub.status.idle":"2025-05-17T21:51:42.993054Z","shell.execute_reply.started":"2025-05-17T21:51:42.989587Z","shell.execute_reply":"2025-05-17T21:51:42.992465Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 3) load PaliGemma-3B-pt-224\nmodel_id = \"google/paligemma-3b-mix-224\"\nmodel    = PaliGemmaForConditionalGeneration.from_pretrained(model_id).to(device).eval()\nprocessor = AutoProcessor.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:51:42.993654Z","iopub.execute_input":"2025-05-17T21:51:42.993869Z","iopub.status.idle":"2025-05-17T21:52:39.346615Z","shell.execute_reply.started":"2025-05-17T21:51:42.993854Z","shell.execute_reply":"2025-05-17T21:52:39.345998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0201a3a5cfd04a2aaab9d8e8501c515e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b689a7844a0841818671731293596552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf8336239e74f73ae258d2d8b2e2c74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297dbdfd6f174db4a9b14a406058cc0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a2b42a71f9457cacc83ee4a3fa9561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8945801179694b248a7733ff5346d178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"213b762685c945449ae873d0c1cbe89f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed18f77dfd384593b0e84a11b5e20160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ae4746fdc542a39dd4ee0191445400"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1814295467964c72b94b7c87d65b1ebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6d003e87a44d21a1f8d5fd07f2436b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d96e0f87477400eafd4b034d58a421b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c3fa44d852a4f089da62707df41dc74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/607 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add68646b11b419eba0cb49b7e29c564"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n# 4) inference loop with progress bar\npreds, refs = [], []\nimage_root  = \"/kaggle/input/test-data-dataset/images\"\n\nstart_time = time.time()\n\nfor _, row in tqdm(df.iterrows(), total=len(df), desc=\"PaliGemma Inference\"):\n    # load & preprocess image\n    img_path = os.path.join(image_root, row[\"path\"])\n    image    = Image.open(img_path).convert(\"RGB\")\n    \n     # build the prompted question with the required <image> token\n    question    = row[\"question\"]\n    # 1 <image> token because you have 1 image\n    prompt_text = f\"<image> Answer in exactly one word: {question}\"\n    \n    # tokenize image + prompt\n    inputs    = processor(text=prompt_text, images=image, return_tensors=\"pt\").to(device)\n    input_len = inputs[\"input_ids\"].shape[-1]\n    \n    # generate (greedy)\n    with torch.inference_mode():\n        output_ids = model.generate(**inputs, max_new_tokens=20, do_sample=False)\n    \n    # decode only the answer portion\n    answer_ids = output_ids[0, input_len:]\n    pred       = processor.decode(answer_ids, skip_special_tokens=True).strip()\n    \n    preds.append(pred)\n    refs .append(str(row[\"answer\"]).strip())\n\nend_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T21:54:30.577601Z","iopub.execute_input":"2025-05-17T21:54:30.577871Z","iopub.status.idle":"2025-05-17T23:08:08.734297Z","shell.execute_reply.started":"2025-05-17T21:54:30.577851Z","shell.execute_reply":"2025-05-17T23:08:08.733396Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"PaliGemma Inference:   0%|          | 0/5994 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f59bbe14ae3446c89db1af7ba249951"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# 5) compute metrics\ntotal_time    = end_time - start_time\navg_time_ms   = total_time / len(preds) * 1000\n\n# Exact‐Match Accuracy\nexact_match = sum(p.lower()==r.lower() for p,r in zip(preds, refs)) / len(preds)\n\n# BERTScore F1 (all preds)\nP_all, R_all, F1_all = score(preds, refs, lang=\"en\", rescale_with_baseline=True)\nbert_f1_all = F1_all.mean().item()\n\n# One‐word analysis\nis_one_word  = [((\" \" not in p) and p!= \"\") for p in preds]\npct_one_word = sum(is_one_word) / len(preds) * 100\npreds_1w     = [p for p, ok in zip(preds, is_one_word) if ok]\nrefs_1w      = [r for r, ok in zip(refs,  is_one_word) if ok]\n\nif preds_1w:\n    _, _, F1_1w = score(preds_1w, refs_1w, lang=\"en\", rescale_with_baseline=True)\n    bert_f1_1w = F1_1w.mean().item()\nelse:\n    bert_f1_1w = float(\"nan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:08:08.735505Z","iopub.execute_input":"2025-05-17T23:08:08.735721Z","iopub.status.idle":"2025-05-17T23:08:29.042214Z","shell.execute_reply.started":"2025-05-17T23:08:08.735699Z","shell.execute_reply":"2025-05-17T23:08:29.041609Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6876361c85f40bb8a9750716399ea44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ce02258e7b4a5caa699632b52d6f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24be951eb654486384c41cd605693740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcaebd27eb5440dbe7e2efd3d59f6e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca9358275a4a46ee86729ae0b76a75e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4d5daf95ec462e8d95f69455943545"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 6) compute BERTScore F1\nP, R, F1 = score(preds, refs, lang=\"en\", rescale_with_baseline=True)# 6) report\nprint(f\"Total inference time (1000 samples): {total_time:.1f}s\")\nprint(f\"Average per sample:                {avg_time_ms:.1f}ms\\n\")\nprint(f\"Exact-Match Accuracy:              {exact_match:.2f}\")\nprint(f\"BERTScore F1 (all preds):          {bert_f1_all:.2f}\\n\")\nprint(f\"% One-Word Predictions:            {pct_one_word:.2f}%\")\nprint(f\"BERTScore F1 (one-word only):      {bert_f1_1w:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:17:23.313973Z","iopub.execute_input":"2025-05-17T23:17:23.314448Z","iopub.status.idle":"2025-05-17T23:17:27.151621Z","shell.execute_reply.started":"2025-05-17T23:17:23.314424Z","shell.execute_reply":"2025-05-17T23:17:27.151007Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Total inference time (1000 samples): 4418.2s\nAverage per sample:                737.1ms\n\nExact-Match Accuracy:              0.63\nBERTScore F1 (all preds):          0.79\n\n% One-Word Predictions:            93.03%\nBERTScore F1 (one-word only):      0.84\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}