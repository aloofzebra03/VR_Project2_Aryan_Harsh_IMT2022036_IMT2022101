{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0) install BERTScore\n!pip --quiet install bert-score\n!pip --quiet install qwen-vl-utils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:29:44.158412Z","iopub.execute_input":"2025-05-16T19:29:44.158600Z","iopub.status.idle":"2025-05-16T19:31:05.404832Z","shell.execute_reply.started":"2025-05-16T19:29:44.158583Z","shell.execute_reply":"2025-05-16T19:31:05.404117Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom bert_score import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:31:05.406665Z","iopub.execute_input":"2025-05-16T19:31:05.406897Z","iopub.status.idle":"2025-05-16T19:31:29.659313Z","shell.execute_reply.started":"2025-05-16T19:31:05.406874Z","shell.execute_reply":"2025-05-16T19:31:29.658750Z"}},"outputs":[{"name":"stderr","text":"2025-05-16 19:31:18.191137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747423878.376980      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747423878.441796      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1) loading QA dataset\ndf = pd.read_csv(\"/kaggle/input/test-data-curation/qa_dataset.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:31:29.659991Z","iopub.execute_input":"2025-05-16T19:31:29.660586Z","iopub.status.idle":"2025-05-16T19:31:29.682622Z","shell.execute_reply.started":"2025-05-16T19:31:29.660565Z","shell.execute_reply":"2025-05-16T19:31:29.682077Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 2) device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:31:29.683328Z","iopub.execute_input":"2025-05-16T19:31:29.683584Z","iopub.status.idle":"2025-05-16T19:31:29.715431Z","shell.execute_reply.started":"2025-05-16T19:31:29.683562Z","shell.execute_reply":"2025-05-16T19:31:29.714854Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n    torch_dtype=torch.float16,   # or bfloat16 if that’s what you want\n    # no device_map\n)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n\n# set padding as before\nprocessor.tokenizer.pad_token     = processor.tokenizer.eos_token\nprocessor.tokenizer.padding_side  = \"left\"\n\nmodel = model.to(device).eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:31:29.716223Z","iopub.execute_input":"2025-05-16T19:31:29.716561Z","iopub.status.idle":"2025-05-16T19:32:35.167570Z","shell.execute_reply.started":"2025-05-16T19:31:29.716539Z","shell.execute_reply":"2025-05-16T19:32:35.166495Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9cde4d7c6784824aa523c3a3f6f8dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd9c1c4b96f43f6bbfaf6c978afa5af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c1f04908e04944834ed31ef73d677e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8eca72ca677432ab9350e34a50b52e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fbc1248a9ec4b63862bf5e76a4b4265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42121a4731c149239dc81745ef29ad72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13b69867ca6463bb789bc3548d9ac1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa23aa6fc12048f79fc1a7b0993d7e0a"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/5.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cd744620ba43609988f7f8b551bf2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd19b7d9099148dbac61d31cb632731e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54792137830f41ca8582547c4dba428b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93dcd3c6a1304285a8fbbe32a8173be8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"506efa8dc126444e833ca5a8f20cdd52"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import math\n\n# 1) parameters\nbatch_size  = 16\npreds, refs = [], []\nimage_root  = \"/kaggle/input/test-data-dataset/images\"\nn_samples   = len(df)\nn_batches   = math.ceil(n_samples / batch_size)\n\n# 2) batched inference\nstart_time = time.time()\nfor batch_start in tqdm(range(0, n_samples, batch_size),\n                        total=n_batches,\n                        desc=\"Qwen2.5-VL-3B-Instruct Batched Inference\"):\n    batch_df = df.iloc[batch_start : batch_start + batch_size]\n\n    # 2a) build list of “chat” messages for the batch\n    batch_messages = []\n    for _, row in batch_df.iterrows():\n        img = Image.open(os.path.join(image_root, row[\"path\"])).convert(\"RGB\").resize((256, 256))\n        batch_messages.append([\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\",  \"text\":  row[\"question\"]}\n            ]}\n        ])\n\n    # 2b) apply the chat template in batch\n    batch_texts = [\n        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n        for msg in batch_messages\n    ]\n\n    # 2c) extract vision inputs for the whole batch\n    image_inputs, video_inputs = process_vision_info(batch_messages)\n\n    # 2d) tokenize the entire batch at once\n    inputs = processor(\n        text=batch_texts,\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n    ).to(device)\n\n    # 2e) generate in one shot\n    with torch.inference_mode():\n        generated = model.generate(**inputs, max_new_tokens=32)\n\n    # 2f) decode each example, trimming off the prompt\n    for in_ids, out_ids in zip(inputs.input_ids, generated):\n        trimmed_ids = out_ids[len(in_ids):]\n        text_out   = processor.batch_decode(\n            [trimmed_ids],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=False\n        )[0].strip()\n        preds.append(text_out)\n    # 2g) collect references\n    refs.extend(batch_df[\"answer\"].astype(str).str.strip().tolist())\n\nend_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:32:35.168481Z","iopub.execute_input":"2025-05-16T19:32:35.168776Z","iopub.status.idle":"2025-05-16T20:15:18.969370Z","shell.execute_reply.started":"2025-05-16T19:32:35.168753Z","shell.execute_reply":"2025-05-16T20:15:18.968615Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Qwen2.5-VL-3B-Instruct Batched Inference:   0%|          | 0/375 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6eaf8bba62d4a829aaceee75a3bc99a"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# # 4) inference loop with timing\n# preds, refs = [], []\n# image_root  = \"/kaggle/input/test-data-dataset/images\"\n\n# start_time = time.time()\n# for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Qwen2-VL Inference\"):\n#     # load & preprocess image\n#     img_path = os.path.join(image_root, row[\"path\"])\n#     image    = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n    \n#     # build the chat‐style message\n#     messages = [\n#         {\n#             \"role\": \"user\",\n#             \"content\": [\n#                 {\"type\": \"image\", \"image\": image},\n#                 {\"type\": \"text\",  \"text\":  row[\"question\"]}\n#             ],\n#         }\n#     ]\n#     # apply template\n#     text = processor.apply_chat_template(\n#         messages, tokenize=False, add_generation_prompt=True\n#     )\n#     # extract vision inputs\n#     image_inputs, video_inputs = process_vision_info(messages)\n#     # tokenize & move to device\n#     inputs = processor(\n#         text=[text],\n#         images=image_inputs,\n#         videos=video_inputs,\n#         padding=True,\n#         return_tensors=\"pt\",\n#     ).to(device)\n\n#     # generate\n#     with torch.inference_mode():\n#         generated_ids = model.generate(**inputs, max_new_tokens=32)\n\n#     # trim off prompt tokens\n#     trimmed_ids = [\n#         out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n#     ]\n#     output_text = processor.batch_decode(\n#         trimmed_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n#     )\n#     pred = output_text[0].strip()\n\n#     preds.append(pred)\n#     refs.append(str(row[\"answer\"]).strip())\n\n# end_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:15:18.971235Z","iopub.execute_input":"2025-05-16T20:15:18.971556Z","iopub.status.idle":"2025-05-16T20:15:18.976200Z","shell.execute_reply.started":"2025-05-16T20:15:18.971535Z","shell.execute_reply":"2025-05-16T20:15:18.975435Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# 5) compute metrics\ntotal_time    = end_time - start_time\navg_time_ms   = total_time / len(preds) * 1000\n\n# Exact‐Match Accuracy\nexact_match = sum(p.lower()==r.lower() for p,r in zip(preds, refs)) / len(preds)\n\n# BERTScore F1 (all preds)\nP_all, R_all, F1_all = score(preds, refs, lang=\"en\", rescale_with_baseline=True)\nbert_f1_all = F1_all.mean().item()\n\n# One‐word analysis\nis_one_word  = [((\" \" not in p) and p!= \"\") for p in preds]\npct_one_word = sum(is_one_word) / len(preds) * 100\npreds_1w     = [p for p, ok in zip(preds, is_one_word) if ok]\nrefs_1w      = [r for r, ok in zip(refs,  is_one_word) if ok]\n\nif preds_1w:\n    _, _, F1_1w = score(preds_1w, refs_1w, lang=\"en\", rescale_with_baseline=True)\n    bert_f1_1w = F1_1w.mean().item()\nelse:\n    bert_f1_1w = float(\"nan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:15:18.976948Z","iopub.execute_input":"2025-05-16T20:15:18.977214Z","iopub.status.idle":"2025-05-16T20:15:49.678436Z","shell.execute_reply.started":"2025-05-16T20:15:18.977184Z","shell.execute_reply":"2025-05-16T20:15:49.677598Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59c3eb8dab8d41618116632662f4e761"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f4b0e4578f43a68d11299b3c4d6b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2112624ab0fe4e0287c52804d5858f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a01ddb39356242a793ef073da2fd2e45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5331b453b832482fa502179483a57c17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54fdc1c5845f40ddb2d0b4d947036f53"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 6) report\nprint(f\"Total inference time (1000 samples): {total_time:.1f}s\")\nprint(f\"Average per sample:                {avg_time_ms:.1f}ms\\n\")\nprint(f\"Exact-Match Accuracy:              {exact_match:.2f}\")\nprint(f\"BERTScore F1 (all preds):          {bert_f1_all:.2f}\\n\")\nprint(f\"% One-Word Predictions:            {pct_one_word:.2f}%\")\nprint(f\"BERTScore F1 (one-word only):      {bert_f1_1w:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:15:49.679273Z","iopub.execute_input":"2025-05-16T20:15:49.679536Z","iopub.status.idle":"2025-05-16T20:15:49.684635Z","shell.execute_reply.started":"2025-05-16T20:15:49.679509Z","shell.execute_reply":"2025-05-16T20:15:49.683966Z"}},"outputs":[{"name":"stdout","text":"Total inference time (1000 samples): 2563.8s\nAverage per sample:                427.7ms\n\nExact-Match Accuracy:              0.00\nBERTScore F1 (all preds):          -0.13\n\n% One-Word Predictions:            0.00%\nBERTScore F1 (one-word only):      nan\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}